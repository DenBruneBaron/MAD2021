{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling and Analysis of Data\n",
    "# Exam 2022 : Date  17th - 25th of January\n",
    "# Exam no: 39\n",
    "\n",
    "# Question 6 (Classification & Validation, 4 points)\n",
    "# Question A and B\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training targets: (252,)\n",
      "Shape of training features: (252, 12)\n",
      "Shape of validation targets: (77,)\n",
      "Shape of validation features: (77, 12)\n",
      "\n",
      "Accuracy score: 0.51\n",
      "Average probability assigned to correct classes: 0.36\n",
      "Accuracy score: 0.70\n",
      "Average probability assigned to correct classes: 0.48\n",
      "{'criterion': 'gini', 'max_features': 'sqrt', 'max_tree_depth': 5}\n",
      "Accuracy score: 0.73\n",
      "Average probability assigned to correct classes: 0.51\n",
      "{'criterion': 'gini', 'max_features': 'sqrt', 'max_tree_depth': 6}\n",
      "Accuracy score: 0.78\n",
      "Average probability assigned to correct classes: 0.56\n",
      "{'criterion': 'gini', 'max_features': 'sqrt', 'max_tree_depth': 10}\n",
      "Accuracy score: 0.78\n",
      "Average probability assigned to correct classes: 0.57\n",
      "{'criterion': 'gini', 'max_features': 'sqrt', 'max_tree_depth': 15}\n",
      "Accuracy score: 0.52\n",
      "Average probability assigned to correct classes: 0.36\n",
      "Accuracy score: 0.70\n",
      "Average probability assigned to correct classes: 0.49\n",
      "Accuracy score: 0.73\n",
      "Average probability assigned to correct classes: 0.51\n",
      "Accuracy score: 0.78\n",
      "Average probability assigned to correct classes: 0.56\n",
      "Accuracy score: 0.78\n",
      "Average probability assigned to correct classes: 0.55\n",
      "Accuracy score: 0.53\n",
      "Average probability assigned to correct classes: 0.37\n",
      "Accuracy score: 0.73\n",
      "Average probability assigned to correct classes: 0.51\n",
      "Accuracy score: 0.79\n",
      "Average probability assigned to correct classes: 0.54\n",
      "{'criterion': 'entropy', 'max_features': 'sqrt', 'max_tree_depth': 6}\n",
      "Accuracy score: 0.82\n",
      "Average probability assigned to correct classes: 0.57\n",
      "{'criterion': 'entropy', 'max_features': 'sqrt', 'max_tree_depth': 10}\n",
      "Accuracy score: 0.82\n",
      "Average probability assigned to correct classes: 0.57\n",
      "{'criterion': 'entropy', 'max_features': 'sqrt', 'max_tree_depth': 15}\n",
      "Accuracy score: 0.56\n",
      "Average probability assigned to correct classes: 0.37\n",
      "Accuracy score: 0.71\n",
      "Average probability assigned to correct classes: 0.51\n",
      "Accuracy score: 0.75\n",
      "Average probability assigned to correct classes: 0.55\n",
      "Accuracy score: 0.84\n",
      "Average probability assigned to correct classes: 0.58\n",
      "{'criterion': 'entropy', 'max_features': 'log2', 'max_tree_depth': 10}\n",
      "Accuracy score: 0.82\n",
      "Average probability assigned to correct classes: 0.57\n",
      "{'criterion': 'gini', 'max_features': 'log2', 'max_tree_depth': 2}\n",
      "{'criterion': 'gini', 'max_features': 'sqrt', 'max_tree_depth': 2}\n",
      "{'criterion': 'entropy', 'max_features': 'sqrt', 'max_tree_depth': 2}\n",
      "{'criterion': 'entropy', 'max_features': 'log2', 'max_tree_depth': 2}\n",
      "{'criterion': 'gini', 'max_features': 'sqrt', 'max_tree_depth': 5}\n",
      "{'criterion': 'gini', 'max_features': 'log2', 'max_tree_depth': 5}\n",
      "{'criterion': 'entropy', 'max_features': 'log2', 'max_tree_depth': 5}\n",
      "{'criterion': 'gini', 'max_features': 'log2', 'max_tree_depth': 6}\n",
      "{'criterion': 'entropy', 'max_features': 'sqrt', 'max_tree_depth': 5}\n",
      "{'criterion': 'gini', 'max_features': 'sqrt', 'max_tree_depth': 6}\n",
      "{'criterion': 'entropy', 'max_features': 'sqrt', 'max_tree_depth': 6}\n",
      "{'criterion': 'entropy', 'max_features': 'log2', 'max_tree_depth': 6}\n",
      "{'criterion': 'gini', 'max_features': 'log2', 'max_tree_depth': 15}\n",
      "{'criterion': 'gini', 'max_features': 'sqrt', 'max_tree_depth': 10}\n",
      "{'criterion': 'gini', 'max_features': 'log2', 'max_tree_depth': 10}\n",
      "{'criterion': 'gini', 'max_features': 'sqrt', 'max_tree_depth': 15}\n",
      "{'criterion': 'entropy', 'max_features': 'sqrt', 'max_tree_depth': 10}\n",
      "{'criterion': 'entropy', 'max_features': 'sqrt', 'max_tree_depth': 15}\n",
      "{'criterion': 'entropy', 'max_features': 'log2', 'max_tree_depth': 15}\n",
      "{'criterion': 'entropy', 'max_features': 'log2', 'max_tree_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "# Modified the loaddata function to make the training features into\n",
    "# 2d np.array, more specifically the 't value'\n",
    "def loaddata(filename):\n",
    "    \"\"\"Load the accent-mfcc-data set from filename and return t, X\n",
    "        t - N-dim. vector of target (temperature) values\n",
    "        X - N-dim. vector containing the inputs (lift) x for each data point\n",
    "    \"\"\"\n",
    "    # Load data set from CSV file\n",
    "    Xt = np.loadtxt(filename, delimiter=\",\")\n",
    "    \n",
    "    # Split into data matrix and target vector\n",
    "    X = Xt[:,0] # Matrix\n",
    "    t = Xt[:,1:] # Vector\n",
    "    \n",
    "    return t, X\n",
    "\n",
    "'''\n",
    "QUESTION 6 - A\n",
    "'''\n",
    "# Loads the training data\n",
    "X_train, t_train = loaddata(\"./accent-mfcc-data_shuffled_train.txt\")\n",
    "\n",
    "# Loads the validation data\n",
    "X_validation, t_validation = loaddata(\"./accent-mfcc-data_shuffled_validation.txt\")\n",
    "\n",
    "\n",
    "print(\"Shape of training targets: %s\" %str(t_train.shape))\n",
    "print(\"Shape of training features: %s\" %str(X_train.shape))\n",
    "print(\"Shape of validation targets: %s\" %str(t_validation.shape))\n",
    "print(\"Shape of validation features: %s\" %str(X_validation.shape))\n",
    "print()\n",
    "\n",
    "\n",
    "'''\n",
    "QUESTION 6 - B\n",
    "'''\n",
    "# Adding the parameters to test given in the exam question.\n",
    "# Using these to find the optimal set of random forest classifier parameters.\n",
    "random_f_parameters = {\n",
    "    'criterion'         : ['gini', 'entropy'],\n",
    "    'max_tree_depth'    : [2,5,6,10,15],\n",
    "    'max_features'      : ['sqrt', 'log2']\n",
    "    }\n",
    "\n",
    "# Empty array for the result metrics\n",
    "metrics_result = np.empty((0,3)) \n",
    "\n",
    "# Looping through the chosen(given) parameters and setting up the\n",
    "# Random forest classifier each time.\n",
    "for parameters in list(ParameterGrid(random_f_parameters)):\n",
    "    rf = RandomForestClassifier(\n",
    "        criterion    = parameters['criterion'],\n",
    "        max_depth    = parameters['max_tree_depth'],\n",
    "        max_features = parameters['max_features'])\n",
    "\n",
    "    # Training using the created classifier with the given parameters.\n",
    "    rf.fit(X_train, t_train)\n",
    "\n",
    "    # number of correctly classified validation samples\n",
    "    t_prediction = rf.predict(X_validation)\n",
    "    acc_score = accuracy_score(t_validation, t_prediction)\n",
    "\n",
    "    # probability associated with classification\n",
    "    t_probability = rf.predict_proba(X_validation)\n",
    "    probability_score = np.mean([t_probability[int(t_val)]\n",
    "                          for (t_probability, t_val)\n",
    "                          in zip(t_probability, t_validation)])\n",
    "\n",
    "    print(\"Accuracy score: %.2f\"\n",
    "        %acc_score)\n",
    "    print(\"Average probability assigned to correct classes: %.2f\"\n",
    "        %probability_score)\n",
    "\n",
    "    # print the parameters if new ones are more optimal \n",
    "    # than previously tried ones.\n",
    "    if len(metrics_result) > 0 and (acc_score > metrics_result[-1,1]\n",
    "                         or (acc_score == metrics_result[-1,1]\n",
    "                             and probability_score > metrics_result[-1,2])):\n",
    "        print(parameters)\n",
    "\n",
    "    # accumulate results\n",
    "    metrics_result = np.append(metrics_result, np.array([[parameters, acc_score, probability_score]]), axis=0)\n",
    "    # sort the results in ascending order\n",
    "    metrics_result = metrics_result[np.lexsort((metrics_result[:,1], metrics_result[:,2]))] \n",
    "\n",
    "for x in metrics_result:\n",
    "    print(x[0])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4fe9a7aa49da7f30e62b4fec1f4aa505596ad3901a02abfd818f434a1ca29ce"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
